{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only for this notebook\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict\n",
    "\n",
    "import ray\n",
    "\n",
    "## Package\n",
    "from ezRay import MultiCoreExecutionTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Specify ezRay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Metadata:\n",
      "{'instance_metadata': {'address': None, 'num_cpus': 1, 'num_gpus': 0},\n",
      " 'task_metadata': {'num_cpus': 1, 'num_gpus': 0, 'num_returns': 1}}\n",
      "\n",
      "\n",
      "Example data:\n",
      "{0: {'ID': 0},\n",
      " 1: {'ID': 1},\n",
      " 2: {'ID': 2},\n",
      " 3: {'ID': 3},\n",
      " 4: {'ID': 4},\n",
      " 5: {'ID': 5},\n",
      " 6: {'ID': 6},\n",
      " 7: {'ID': 7},\n",
      " 8: {'ID': 8},\n",
      " 9: {'ID': 9}}\n"
     ]
    }
   ],
   "source": [
    "## Instance metadata\n",
    "##### IMPORTANT: In this step you can apecify any other keyword argument labeled \"for remote functions\"\n",
    "##### found in https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html.\n",
    "\n",
    "# -> 'num_cpu' is the number of virtual CPU cores to link with your instance.\n",
    "# -> 'num_gpu' is the number of GPU devices to link with your instance.\n",
    "# -> 'address' is the address of the Ray cluster to connect to. If None, a new cluster will be created locally.\n",
    "instance_metadata: dict = {\"num_cpus\": 1, \"num_gpus\": 0, \"address\": None}\n",
    "\n",
    "## Task metadata\n",
    "##### IMPORTANT: In this step you can specify any other keyword argument labeled \"for remote functions\"\n",
    "##### found in https://docs.ray.io/en/latest/ray-core/api/doc/ray.remote.html.\n",
    "\n",
    "# We keep a few default values for the task metadata.\n",
    "# -> 'num_cpus' is the number of CPU cores to allocate for each task.\n",
    "# -> 'num_gpus' is the number of GPU devices to allocate for each task.\n",
    "# -> 'num_returns' is the number of return values from each task.\n",
    "\n",
    "task_metadata: dict = {\"num_cpus\": 1, \"num_gpus\": 0, \"num_returns\": 1}\n",
    "\n",
    "## Behavioral flags\n",
    "# -> 'AutoArchive' is a boolean flag that will force the archiving of results when between runs and upon data update.\n",
    "# -> 'AutoContinue' is a boolean flag that will force the tool to automatically prepare for the next run after the current run is completed. If AutoArchive is enabled, the tool will automatically archive the results before preparing for the next run.\n",
    "# -> 'SingleShot' is a boolean flag that will force the tool to run once and return the results. Archiving will be disabled and the next run automatically prepared. This is meant to be used if the tool is used as a function or part of a pipeline.\n",
    "# -> 'AutoLaunchDashboard' is a boolean flag to launch the Dask dashboard on cluster initialization.\n",
    "# -> 'ListenerSleeptime' adds an artificial delay when monitoring the cluster status.\n",
    "# -> 'silent' is a boolean flag to suppress all output.\n",
    "# -> 'DEBUG' is a boolean flag to enable debug output.\n",
    "verbosity_flags: dict = {\n",
    "    \"AutoArchive\": True,\n",
    "    \"AutoContinue\": False,\n",
    "    \"SingleShot\": False,\n",
    "    \"AutoLaunchDashboard\": False,\n",
    "    \"ListenerSleeptime\": 0.0,\n",
    "    \"silent\": False,\n",
    "    \"DEBUG\": False,\n",
    "}\n",
    "\n",
    "## Assembly\n",
    "RuntimeMetadata: Dict[str, Any] = {\n",
    "    \"instance_metadata\": instance_metadata,\n",
    "    \"task_metadata\": task_metadata,\n",
    "}\n",
    "print(\"Runtime Metadata:\")\n",
    "pprint(RuntimeMetadata)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Example data\n",
    "RuntimeData: dict = {i: {\"ID\": i} for i in range(10)}\n",
    "print(\"Example data:\")\n",
    "pprint(RuntimeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize ezRay Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 12:45:25,320\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "## We create a MultiCoreExecutionTool instance\n",
    "# -> We can either directly provice the RuntimeData or use the 'update_data' method to add data\n",
    "MultiCore: MultiCoreExecutionTool = MultiCoreExecutionTool(\n",
    "    RuntimeData, **RuntimeMetadata, **verbosity_flags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update data\n",
    "# -> We can either directly provice the RuntimeData or use the 'update_data' method to add data\n",
    "# e.g.\n",
    "MultiCore.update_data(RuntimeData)\n",
    "\n",
    "## Update metadata\n",
    "# -> We can update the task metadata using the 'update_metadata' method\n",
    "# e.g.\n",
    "MultiCore.update_metadata(\n",
    "    task_metadata={\"num_cpus\": 1, \"num_gpus\": 0, \"num_returns\": 1},\n",
    "    instance_metadata={\"num_cpus\": 1, \"num_gpus\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5: Launch ray dashboard (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lauching the dashboard to keep track of the cluster and the tasks\n",
    "MultiCore.launch_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run ezRay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb2c9ff5126491087c4e40cf7c69eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scheduling Workers:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31eeb5aed0748d095a8b0b467c1bebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Workers:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aee46be2ac54fc59aa23aa481bead84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CPU usage:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fb62a78bdb452a9b22e52a1f83c2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RAM usage:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'result': {'ID': 0}, 'status': 'retrieved'},\n",
      " 1: {'result': {'ID': 1}, 'status': 'retrieved'},\n",
      " 2: {'result': {'ID': 2}, 'status': 'retrieved'},\n",
      " 3: {'result': {'ID': 3}, 'status': 'retrieved'},\n",
      " 4: {'result': {'ID': 4}, 'status': 'retrieved'},\n",
      " 5: {'result': {'ID': 5}, 'status': 'retrieved'},\n",
      " 6: {'result': {'ID': 6}, 'status': 'retrieved'},\n",
      " 7: {'result': {'ID': 7}, 'status': 'retrieved'},\n",
      " 8: {'result': {'ID': 8}, 'status': 'retrieved'},\n",
      " 9: {'result': {'ID': 9}, 'status': 'retrieved'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run a ray-remote testfunction\n",
    "# We can forward any ray-remote function to the MultiCoreExecutionTool instance.\n",
    "# The function will be executed on the remote cluster.\n",
    "# The function must be defined in a separate module or script.\n",
    "\n",
    "## DEMO function\n",
    "# this will just return the input dictionary in a structured manner\n",
    "@ray.remote(num_cpus=1, num_returns=1)\n",
    "def remote_test_function(kwargs) -> Dict[Any, Any]:\n",
    "    \"\"\"Test function for the framework that merely forwards the input.\"\"\"\n",
    "    return {k: v for k, v in kwargs.items()}\n",
    "\n",
    "\n",
    "## Pass the function to the MultiCoreExecutionTool instance\n",
    "MultiCore.run(remote_test_function)\n",
    "\n",
    "## Get the results\n",
    "pprint(MultiCore.get_results())\n",
    "\n",
    "## Move to next task\n",
    "MultiCore.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b385ecdc88d74f17aac90341189a93b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scheduling Workers:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e03811eaa92424b915b1f945e911341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Workers:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a55b3cb9d364abeb78f57d3de23deca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CPU usage:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694ae5f8cf464e50a87d319a1197b976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RAM usage:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'result': {'ID': 0}, 'status': 'retrieved'},\n",
      " 1: {'result': {'ID': 1}, 'status': 'retrieved'},\n",
      " 2: {'result': {'ID': 2}, 'status': 'retrieved'},\n",
      " 3: {'result': {'ID': 3}, 'status': 'retrieved'},\n",
      " 4: {'result': {'ID': 4}, 'status': 'retrieved'},\n",
      " 5: {'result': {'ID': 5}, 'status': 'retrieved'},\n",
      " 6: {'result': {'ID': 6}, 'status': 'retrieved'},\n",
      " 7: {'result': {'ID': 7}, 'status': 'retrieved'},\n",
      " 8: {'result': {'ID': 8}, 'status': 'retrieved'},\n",
      " 9: {'result': {'ID': 9}, 'status': 'retrieved'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run a local test function\n",
    "# We can also run a local function on the remote cluster.\n",
    "# The function must be defined in a separate module or script.\n",
    "# The function will be wrapped as a remote worker and then passed to the MultiCoreExecutionTool instance.\n",
    "\n",
    "## DEMO function\n",
    "# this will just return the input dictionary in a structured manner\n",
    "def local_test_function(**kwargs):\n",
    "    return {k: v for k, v in kwargs.items()}\n",
    "\n",
    "\n",
    "## Pass the function to the MultiCoreExecutionTool instance\n",
    "MultiCore.run(local_test_function)\n",
    "\n",
    "## Get the results\n",
    "pprint(MultiCore.get_results())\n",
    "\n",
    "## Move to next task\n",
    "MultiCore.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cbf8e74d9547cba9f804eaba554a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scheduling Workers:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c748f2bee919419b8b88dc55192b5fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Workers:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b295d19baaea4030bdab465ed6381bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CPU usage:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d976d94fa4442db9254ea48b2b97a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RAM usage:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending results found. Use the \"run()\" method to get results.\n",
      "{0: {'result': {'ID': 0}, 'status': 'retrieved'},\n",
      " 1: {'result': {'ID': 1}, 'status': 'retrieved'},\n",
      " 2: {'result': None, 'status': 'pending'},\n",
      " 3: {'result': None, 'status': 'pending'},\n",
      " 4: {'result': None, 'status': 'pending'},\n",
      " 5: {'result': None, 'status': 'pending'},\n",
      " 6: {'result': None, 'status': 'pending'},\n",
      " 7: {'result': None, 'status': 'pending'},\n",
      " 8: {'result': None, 'status': 'pending'},\n",
      " 9: {'result': None, 'status': 'pending'}}\n",
      "Pending results found. Continuing to next task.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run in batch mode\n",
    "# We can run multiple functions in batch mode.\n",
    "# The functions must be defined in a separate module or script.\n",
    "\n",
    "## DEMO function\n",
    "# this will just return the input dictionary in a structured manner\n",
    "def local_test_function(**kwargs):\n",
    "    return {k: v for k, v in kwargs.items()}\n",
    "\n",
    "\n",
    "## Pass the function to the MultiCoreExecutionTool instance\n",
    "MultiCore.batch(local_test_function, runIDs=2)\n",
    "\n",
    "## Get the results\n",
    "pprint(MultiCore.get_results())\n",
    "\n",
    "## Move to next task\n",
    "MultiCore.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiCore.archive_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dont forget to shutdown the cluster after use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shutdown the cluster\n",
    "MultiCore.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezRay_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
